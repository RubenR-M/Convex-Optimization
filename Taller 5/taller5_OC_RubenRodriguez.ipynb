{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import hilbert\n",
    "from sklearn.datasets import make_sparse_spd_matrix, make_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(A: list, size: int) -> None:\n",
    "    print(f'\\nGradient Descent')\n",
    "    print('-----------------')\n",
    "    n = size\n",
    "    # print(\"Tamano: \", n)\n",
    "    A = A\n",
    "    # x = np.random.randint(1, 10, size=(n, 1))\n",
    "    x_k = np.zeros((n, 1))\n",
    "\n",
    "    b = np.ones((n, 1))  # A@x\n",
    "\n",
    "    y = b - A@x_k\n",
    "    k=1\n",
    "    while np.linalg.norm(y) > 1e-6:\n",
    "        grad1 = A.T@(A@x_k - b)\n",
    "        pGrad1 = -grad1\n",
    "        \n",
    "        alpha = 1\n",
    "        c = 0.01\n",
    "        \n",
    "        condicionIzq = np.linalg.norm(b - A@(x_k+(alpha*pGrad1)))\n",
    "        condicionDer = np.linalg.norm(b - A@x_k) + (alpha*c*((grad1.T@pGrad1)))\n",
    "\n",
    "        while condicionIzq > condicionDer:\n",
    "            alpha = 0.9*alpha\n",
    "\n",
    "            condicionIzq = np.linalg.norm(b - A@(x_k+(alpha*pGrad1)))\n",
    "            condicionDer = np.linalg.norm(b - A@x_k) + (alpha*c*((grad1.T@pGrad1)))\n",
    "\n",
    "        x_k += alpha*pGrad1\n",
    "        y = b - A@x_k\n",
    "        \n",
    "        if k % 50000 == 0:\n",
    "            # print(\"Funcion:{}\\tAlpha:{}\\tX_k:{}\\tnorma={}\".format(funcion(A, x_k), alpha, x_k, np.linalg.norm(x_k-x)))\n",
    "            print(f\"k:{k} norma={np.linalg.norm(y)}\")\n",
    "        k=k+1\n",
    "        \n",
    "    print(f\"k:{k} norma={np.linalg.norm(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(A: list, size: int) -> None:\n",
    "    print(f'\\nNewton')\n",
    "    print('-----------------')\n",
    "    \n",
    "    n = size\n",
    "    # print(\"Tamano: \", n)\n",
    "    A = A\n",
    "    # x = np.random.randint(1, 10, size=(n, 1))\n",
    "    x_k = np.zeros((n, 1))\n",
    "\n",
    "    b = np.ones((n, 1))  # A@x\n",
    "\n",
    "    y = A@x_k-b\n",
    "    k = 0\n",
    "    \n",
    "    while np.linalg.norm(y) > 1e-6:\n",
    "        grad1 = (A@x_k - b)\n",
    "        pGrad1 = np.linalg.inv(-A.T)@grad1\n",
    "\n",
    "        alpha = 1\n",
    "        # c = 0.01\n",
    "        # condicionIzq = np.linalg.norm(b - A@(x_k+(alpha*pGrad1)))\n",
    "        # condicionDer = np.linalg.norm(b - A@x_k) + (alpha*c*((grad1.T@pGrad1)))\n",
    "\n",
    "        # while condicionIzq > condicionDer:\n",
    "        #     alpha = 0.9*alpha\n",
    "\n",
    "        #     condicionIzq = np.linalg.norm(b - A@(x_k+(alpha*pGrad1)))\n",
    "        #     condicionDer = np.linalg.norm(b - A@x_k) + (alpha*c*((grad1.T@pGrad1)))\n",
    "        \n",
    "        x_k += alpha*pGrad1\n",
    "        y = A@x_k - b\n",
    "        # if i % 100 == 0:\n",
    "        #     print(\"Funcion:{}\\tAlpha:{}\\tX1:{}\\t X2:{}\".format(funcion(x1, x2), alpha, x1, x2))\n",
    "        \n",
    "    print(f\"k:{k} norma={np.linalg.norm(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_conjugateGradient(A: list, size: int) -> None:\n",
    "    print(\"\\nPRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\")\n",
    "    print(\"------------------------------------------------\")\n",
    "    n = size\n",
    "    # print(f'tamaño n: ({n})')\n",
    "    A = A\n",
    "    x = np.random.randint(1, 10, size=(n, 1))\n",
    "    x_k = np.zeros((n, 1))\n",
    "\n",
    "    b = np.ones((n, 1))#np.dot(A, x)\n",
    "\n",
    "    r = np.dot(A, x_k) - b\n",
    "    p = -r\n",
    "    k = 0\n",
    "\n",
    "    alpha = 1\n",
    "\n",
    "    while np.linalg.norm(r) > 1e-6:\n",
    "        \n",
    "        alpha = -np.dot(r.T,p) / np.dot(np.dot(p.T,A),p)\n",
    "        \n",
    "        x_k = x_k + alpha*p\n",
    "        \n",
    "        r = np.dot(A,x_k) - b\n",
    "        \n",
    "        beta = np.dot(np.dot(r.T,A),p) / np.dot(np.dot(p.T,A),p)\n",
    "        \n",
    "        p = -r + beta*p\n",
    "        k += 1\n",
    "    print(f'k: {k} iteraciones, norm(r): {np.linalg.norm(r)}')\n",
    "        \n",
    "\n",
    "# print(\"\\nSymmetric definite positive matrix.\")\n",
    "# pre_conjugateGradient(make_spd_matrix, [5, 10, 20, 50, 100])\n",
    "\n",
    "# print(\"\\nSparse symmetric definite positive matrix.\")\n",
    "# pre_conjugateGradient(make_sparse_spd_matrix, [5, 10, 20, 50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugateGradient(A: list, size: int) -> None:\n",
    "    # PRACTICAL FORM OF THE CONJUGATE GRADIENT METHOD\n",
    "    print(\"\\nPRACTICAL FORM - CONJUGATE GRADIENT METHOD\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    n=size\n",
    "    # print(f'tamaño n: ({n})')\n",
    "    A = A\n",
    "    x = np.random.randint(1, 10, size=(n, 1))\n",
    "    x_k = np.zeros((n,1))\n",
    "\n",
    "    b = np.ones((n, 1))  # np.dot(A,x)\n",
    "\n",
    "    r = np.dot(A,x_k) - b\n",
    "    p = -r\n",
    "    k=0\n",
    "\n",
    "    alpha = 1\n",
    "\n",
    "    while np.linalg.norm(r) >= 10**(-6):\n",
    "        aux = r\n",
    "        alpha = np.dot(r.T, r)/np.dot(np.dot(p.T, A), p)\n",
    "\n",
    "        x_k = x_k + alpha*p\n",
    "\n",
    "        r = r + alpha*np.dot(A,p)\n",
    "\n",
    "        beta = np.dot(r.T, r)/np.dot(aux.T, aux)\n",
    "\n",
    "        p = -r + beta*p\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    print(f'k={k} iteraciones, norma={np.linalg.norm(r)}')\n",
    "    \n",
    "# print(\"\\nSymmetric definite positive matrix.\")\n",
    "# conjugateGradient(make_spd_matrix, [5, 10, 20, 50, 100])\n",
    "\n",
    "# print(\"\\nSparse symmetric definite positive matrix.\")\n",
    "# conjugateGradient(make_sparse_spd_matrix, [5, 10, 20, 50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tamaño n: (3)\n",
      "\n",
      "PRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\n",
      "------------------------------------------------\n",
      "k: 3 iteraciones, norm(r): 1.9166552802820876e-13\n",
      "\n",
      "tamaño n: (5)\n",
      "\n",
      "PRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\n",
      "------------------------------------------------\n",
      "k: 6 iteraciones, norm(r): 1.030537680680428e-07\n",
      "\n",
      "tamaño n: (8)\n",
      "\n",
      "PRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\n",
      "------------------------------------------------\n",
      "k: 29 iteraciones, norm(r): 2.1769683337563513e-07\n",
      "\n",
      "tamaño n: (10)\n",
      "\n",
      "PRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\n",
      "------------------------------------------------\n",
      "k: 857 iteraciones, norm(r): 9.787519125333376e-07\n"
     ]
    }
   ],
   "source": [
    "# PRIMER PUNTO\n",
    "size = [3,5,8,10]\n",
    "for n in size:\n",
    "    print(f'\\ntamaño n: ({n})')\n",
    "    A = hilbert(n)\n",
    "    pre_conjugateGradient(A, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tamaño n: (3)\n",
      "\n",
      "Gradient Descent\n",
      "-----------------\n",
      "k:4379 norma=9.941228920763843e-07\n",
      "\n",
      "Newton\n",
      "-----------------\n",
      "k:0 norma=5.502048458334071e-15\n",
      "\n",
      "PRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\n",
      "------------------------------------------------\n",
      "k: 3 iteraciones, norm(r): 3.772422827534513e-14\n",
      "\n",
      "tamaño n: (5)\n",
      "\n",
      "Gradient Descent\n",
      "-----------------\n",
      "k:423 norma=8.381903473215445e-07\n",
      "\n",
      "Newton\n",
      "-----------------\n",
      "k:0 norma=3.5178481278552407e-15\n",
      "\n",
      "PRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\n",
      "------------------------------------------------\n",
      "k: 5 iteraciones, norm(r): 6.393391139652317e-13\n",
      "\n",
      "tamaño n: (7)\n",
      "\n",
      "Gradient Descent\n",
      "-----------------\n",
      "k:47102 norma=9.997544528023972e-07\n",
      "\n",
      "Newton\n",
      "-----------------\n",
      "k:0 norma=4.31791126777164e-14\n",
      "\n",
      "PRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\n",
      "------------------------------------------------\n",
      "k: 7 iteraciones, norm(r): 9.017214274476535e-08\n"
     ]
    }
   ],
   "source": [
    "# SEGUNDO PUNTO\n",
    "size = [3,5,7]\n",
    "for n in size:\n",
    "    print(f'\\ntamaño n: ({n})')\n",
    "    A = make_spd_matrix(n)\n",
    "    gradientDescent(A, n)\n",
    "    newton(A,n)\n",
    "    pre_conjugateGradient(A, n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tamaño n: (8)\n",
      "\n",
      "Gradient Descent\n",
      "-----------------\n",
      "k:5254 norma=9.994468718718012e-07\n",
      "\n",
      "Newton\n",
      "-----------------\n",
      "k:0 norma=6.527695982012238e-15\n",
      "\n",
      "PRELIMINARY VERSION - CONJUGATE GRADIENT METHOD\n",
      "------------------------------------------------\n",
      "k: 8 iteraciones, norm(r): 6.736481420771615e-09\n"
     ]
    }
   ],
   "source": [
    "size = [8]\n",
    "for n in size:\n",
    "    print(f'\\ntamaño n: ({n})')\n",
    "    A = make_spd_matrix(n)\n",
    "    gradientDescent(A, n)\n",
    "    newton(A, n)\n",
    "    pre_conjugateGradient(A, n)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
